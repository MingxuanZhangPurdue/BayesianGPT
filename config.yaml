SparsityScheduler:
  name: CubicSparsityScheduler
  params:
    initial_sparsity: 0.1
    final_sparsity: 0.8
    pruning_start_step: 0.1
    pruning_end_step: 0.9
    pruning_interval: 0.01

PriorScheduler:
  name: ConstantPriorScheduler
  params:
    lambda_mix: 0.0001
    sigma0: 0.0000000001
    sigma1: 0.01

Pruner:
  name: UnstructuredBayesianPruner
  params:
    target_modules:
      - transformer.h.*.mlp.c_fc.weight
      - transformer.h.*.mlp.c_proj.weight
      - transformer.h.*.attn.c_attn.weight
      - transformer.h.*.attn.c_proj.weight

MainArguments:
  dataset_name: HuggingFaceFW/fineweb
  dataset_config_name: sample-10BT
  validation_split_percentage: 5
  model_name_or_path: openai-community/gpt2
  per_device_train_batch_size: 16
  learning_rate: 0.00001
  seed: 42
  block_size: 512
  preprocessing_num_workers: 64